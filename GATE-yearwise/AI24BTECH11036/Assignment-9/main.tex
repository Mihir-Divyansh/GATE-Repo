%iffalse
%\section{Questions with two marks each}

%\begin{enumerate}

\iffalse
		\author{ai24btech11036}
		\section{st}
		\chapter{2020}
		\fi

\item Let $X_{1}, \ldots, X_{n}$ be arandom sample size of $n\brak{\geq 2}$ from $N\brak{\theta, 1}$ distribution where $\theta \in \brak{-\infty, \infty}$. Consider the problem of testing $H_{0}: \theta \in \sbrak{1,2}$ against $H_{1}: \theta < 1$ or $\theta > 2$, based on $X_{1}, \ldots, X_{n}$. Which of the following statements is TRUE?

	\hfill{2020-ST}
	\begin{enumerate}
	\item Critical region, of level $\alpha \brak{0<\alpha<1}$ of uniformly most powerful test for $H_{0}$ against $H_{1}$ is of the form $\cbrak{\brak{x_{1}, \ldots, x_{n}}: c_{1} \leq \sum_{i=1}^{n}x_{i} \leq c_{2}}$, where $c_{1}$ and $c_{2}$ are such that the test is of level $\alpha$
	\item Critical region, of level $\alpha \brak{0<\alpha<1}$ of uniformly most powerful test for $H_{0}$ against $H_{1}$ is of the form $\cbrak{\brak{x_{1}, \ldots, x_{n}}: \sum_{i=1}^{n}x_{i}>c \text{ or } \sum_{i=1}^{n}<d}$, where $c$ and $d$ are such that the test is of level $\alpha$
	\item At any level $\alpha \in \brak{0,1}$, uniformly most powerful test for $H_{0}$ against $H_{1}$ does \textbf{NOT} exist
	\item At any level $\alpha \in \brak{0,1}$, uniformly most powerful test for $H_{0}$ against $H_{1}$ is less than $\alpha$	
	\end{enumerate}

\item In a pure birth process with birth rates $\lambda_{n}=2^{n}, n \geq 0$ let the random variable $T$ denote the time taken for the population size to grow from 0 to 5. If Var$\brak{T}$ denotes the variance of the random variable $T$, then
	\begin{align*}
	 	256 \times \text{Var}\brak{T}= \rule{1cm}{0.2pt}
	\end{align*}
\hfill{2020-ST}


\item Let $\cbrak{X_n}_{n\geq 0}$ be a homogenous Markov chain whose state space is $\cbrak{0, 1, 2}$ and whose one-step transition probability matrix
$P=\myvec{ 0 & 1 & 0 \\
	   0.3 & 0 & 0.7 \\
	   0 & 1 & 0}$ Then $\lim_{n\to \infty}P\brak{X_{2n}=2 \vert X_{0} =2}=$ \rule{1cm}{0.2pt} (coorect upto one decimal place).
\hfill{2020-ST}


\item Let $\brak{X, Y}$ be a random vector such that, for any $y>0$, the conditional probability density function of $X$ given $Y=y$ is
	\begin{align*}
		f_{X|Y=y}\brak{x} = y e^{-yx}, x > 0.
	\end{align*}
If the marginal probability density function of $Y$ is
	\begin{align*}
		g\brak{y} = y e^{-y}, y > 0,
	\end{align*}
then $E\brak{Y|X=1}=$ \rule{1cm}{0.2pt} (correct up to one decimal place).
\hfill{2020-ST}


\item Let $\brak{X, Y}$ be a random vector with the joint moment generating function
	\begin{align*}
         M_{X,Y}\cbrak{s, t} = e^{2s^2 + t}, \, -\infty < s, t < \infty.
	\end{align*}
     Let $\Phi\brak{\cdot}$ denote the distribution function of the standard normal distribution and $p=P\brak{X+2Y<1}$. If $\Phi\brak{0}=0.5, \Phi\brak{0.5}=0.6915, \Phi\brak{1}=0.8413$ and $\Phi\brak{1.5}=0.9332$ then the value of $2p+1$ (round off to two decimal places) equals \rule{1cm}{0.2pt}
\hfill{2020-ST}


\item Consider a homogeneous Markov chain $ \cbrak{X_n}_{n \geq 0} $ with state space $ \cbrak{ 0, 1, 2, 3 } $ and one-step transition probability matrix
	\begin{align*}
	P =  \myvec{ \frac{1}{2} & \frac{1}{2} & 0 & 0 \\ \\
		  \frac{1}{2} & \frac{1}{4} & \frac{1}{4} & 0 \\ \\
		   0 & 0 & \frac{1}{3} & \frac{2}{3} \\ \\
			0 & 0 & 0 & 1}
	\end{align*}
	

 Assume that $ P\brak{X_0 = 1} = 1 $. Let $ p $ be the probability that state 0 will be visited before state 3. Then $ 6 \times p = \rule{1cm}{0.2pt} $
\hfill{2020-ST}


\item Let $ (X, Y) $ be a random vector with joint probability mass function

\begin{align*}
f_{X,Y}\brak{x,y} = 
\begin{cases} 
{}^x C_y \left( \frac{1}{4} \right)^x, & y = 0, 1, 2, \ldots, x; \, x = 1, 2, \ldots \\
0, & \text{otherwise}
\end{cases}
\end{align*}

where $ {}^x C_y = \frac{x!}{y!(x - y)!} $. Then the variance of $ Y $ equals \rule{1cm}{0.2pt}.
\hfill{2020-ST}


\item Let $X$ be a discrete random variable with probability mass function $f \in \cbrak{f_0, f_1}$ where
	\begin{table}[ht]
		\centering
		\input{tables/tab1.tex}
	\end{table}
      The power of the most powerful level $\alpha = 0.1$ test for testing $
	H_0 : X \sim f_0$ against $H_1 : X \sim f_1$ based on $X$, equals \rule{1cm}{0.2pt} (correct up to two decimal places).
\hfill{2020-ST}


\item Let $ \underline{X} = \brak{X_1, X_2, X_3} $ be a random vector following $ N_{3}\brak{\underline{0}, \Sigma} $ distribution, where


$\Sigma$ = \myvec{ 1 & \frac{1}{3} & \frac{1}{3} \\ \frac{1}{3} & 1 & \frac{1}{3} \\ \frac{1}{3} & \frac{1}{3} & 1 }. Then the partial correlation coefficient between $ X_2 $ and $ X_3 $, with fixed $ X_1 $, equals \rule{1cm}{0.2pt} (correct up to two decimal places).
\hfill{2020-ST}


\item Let $ X_1, X_2, X_3 $ and $ X_4 $ be a random sample from a population having probability density function $ f_\theta\brak{x} = f\brak{x - \theta}, -\infty < x < \infty, \theta \in \brak{-\infty, \infty} $ and $ f\brak{-x} = f\brak{x} $, for all $ x \in \brak{-\infty, \infty} $. For testing $ H_0 : \theta = 0 $ against $ H_1 : \theta < 0 $, let $ T^+ $ denote the Wilcoxon Signed-rank statistic. Then under $ H_0 $,

	\begin{align*}
		32 \times P\brak{T^+ \leq 5} = \rule{1cm}{0.2pt}.
	\end{align*}
\hfill{2020-ST}


\item A simple linear regression model with unknown intercept and unknown slope is fitted to the following data:
	\begin{table}[ht]
		\centering
		\input{tables/tab2.tex}
	\end{table}
sing the method of ordinary least squares. Then the predicted value of $y$ corresponding to $x=5$ is \rule{1cm}{0.2pt}.
\hfill{2020-ST}


\item Let $ D = \{ \brak{x, y, z} \in \mathbb{R} \times \mathbb{R} \times \mathbb{R} : 0 \leq x, y, z \leq 1, x + y + z \leq 1 \} $, where $ \mathbb{R} $ denotes the set of all real numbers. If

\begin{align*}
I = \iiint_D \brak{x + y} \, dx \, dy \, dz,
\end{align*}

then $ 84 \times I = \rule{1cm}{0.2pt} $.
\hfill{2020-ST}


\item Let the random vector $ \brak{X, Y} $ have the joint distribution function

\begin{align*}
F\brak{x, y} = 
\begin{cases} 
0, & x < 0 \text{ or } y < 0 \\
1 - e^{-x}, & x \geq 0, 0 \leq y < 1 \\
\frac{4 - e^{-x}}{1 - e^{-x}}, & x \geq 0, y \geq 1 
\end{cases}
\end{align*}

Let $ \text{Var}\brak{X} $ and $ \text{Var}\brak{Y} $ denote the variances of random variables $ X $ and $ Y $, respectively. Then

\begin{align*}
16 \, \text{Var}\brak{X} + 32 \, \text{Var}\brak{Y} = \underline{\hspace{1cm}}.
\end{align*}
\hfill{2020-ST}

%\end{enumerate}
%\end{document}

 
