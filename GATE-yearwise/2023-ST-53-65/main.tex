\iffalse
\title{2020-ST-53-65}
\author{EE24BTECH11010 - BALAJI B}
\section{st}
\chapter{2020}
\fi


    \item Let $\brak{X,Y}$ be a random vector such that, for any $ y > 0$, the conditional probability density fuction of $X$ given $Y = y$ is 
    \begin{center}
        $f_{X|Y=y}\brak{x} = ye^{-yx}$, $x > 0.$
    \end{center}
    If the marginal probability density function of $Y$ is 
    \begin{center}
        $g\brak{y} = ye^{-y}$, $y > 0$
    \end{center}
    then $E\brak{Y|X=1} = $ \rule{2cm}{0.4pt} (correct up to one decimal place)

    \hfill [2020 ST]
    \item Let $\brak{X,Y}$ be a random vector with the joint moment generating function 
    \begin{center}
        $M_{X,Y}\brak{s,t} = e^{2s^2 + t}$, $-\infty < s,t < \infty$.
    \end{center}
    Let $\Phi\brak{.}$ denotes the distribution function normal distribution and $p = P\brak{X + 2Y < 1}$. If $\Phi \brak{0} = 0.5$, $\Phi\brak{0.5} = 0.6915$, $\Phi\brak{1} = 0.8413$ and $\Phi \brak{1.5} = 0.9332$ then the value of $2p + 1$ (round off to two decimal places) equals \rule{2cm}{0.4pt}

    \hfill [2020 ST]
    \item Consider a homogeneous Markov chain $\cbrak{X_n}_{n \geq 0}$ with state $\cbrak{0,1,2,3}$ and one-step transition probability matrix 
    \begin{center}
        $P = \myvec{\frac{1}{2} & \frac{1}{2} & 0 & 0 \\ \frac{1}{2} & \frac{1}{4} & \frac{1}{4} & 0 \\
        0 & 0 & \frac{1}{4} & \frac{3}{4} \\ 0 & 0 & 0 & 1}$
    \end{center}
    Assume that $P\brak{X_0 = 1} = 1$. Let $p$ be the probability that state 0 will be visited before 3. Then $6 \times p = $ \rule{2cm}{0.4pt}

    \hfill [2020 ST]
    \item Let $\brak{X,Y}$ be a random vector with joint probability mass function
    \begin{center}
        $f_{X,Y}\brak{x,y} = 
        \begin{cases}
            ^xC_y\brak{\frac{1}{4}}^x & y = 0,1,2 \ldots x\text{ ; } x = 1,2 \ldots \\
            0 & \text{otherwise}
        \end{cases}$
    \end{center}
    where $^xC_y = \frac{x!}{y!(x-y)!}$. Then variance of $Y$ equals \rule{2cm}{0.4pt}

    \hfill [2020 ST]
    \item Let $X$ be a discrete random variable with probability mass function $f \in \cbrak{f_0, f_1}$ where 
    \begin{table}[H]
        \centering
        \begin{tabular}{c|c c c c c}
\hline
     & $x = 1$ & $x = 2 $ & $x = 3$ & $x = 4 $ & $x = 5$\\
     \hline
    $f_0\brak{x}$ & 0.10 & 0.10 & 0.10 & 0.10 & 0.60 \\
    \hline
    $f_1\brak{x}$ & 0.05 & 0.06 & 0.08 & 0.09 & 0.72 \\
    \hline
\end{tabular}
    \end{table}
    The power of the most powerful level $\alpha = 0.1$ test for testing $H_0: X \sim f_0$ against $H_1 : X \sim f_1$, based on $X $, equals \rule{2cm}{0.4pt} (correct up to two decimal places).

    \hfill [2020 ST]
    \item $\vec{X} = \brak{X_1, X_2, X_3}$ be a random vector following $N_3 \brak{\vec{0}, \sum }$ distribution, where $\sum = \myvec{1 & \frac{1}{3} & \frac{1}{3} \\
    \frac{1}{3} & 1 & \frac{1}{3} \\ \frac{1}{3} & \frac{1}{3} & 1}$. Then the partial correlation coefficient between $X_2$ and $X_3$, wuth fixed $X_1$, equals \rule{2cm}{0.4pt} (correct up to two decimal places)

    \hfill [2020 ST]
    \item Let $X_1, X_2 ,X_3$ and $X_4$ be a random sample from a populaion having probability density function $f_{\theta}\brak{x} = f\brak{x - \theta}$, $-\infty < x < \infty$, where $\theta \in \brak{-\infty, \infty}$ and $f(-x) = f(x)$, for all $x \in \brak{- \infty, \infty}$. For testing $H_0 : \theta = 0$ against $H_1 ; \theta = 0$ against $H_1:\theta < 0$ let $T^{+}$ denotes the Wilcoxon Signed-rank statistic. Then under $H_0$,
    \begin{center}
        $32 \times P\brak{T^+ \leq 5} = $\rule{2cm}{0.4pt}
    \end{center}
    
    \hfill [2020 ST]
    \item A simple linear regression model with unknown intercept and unknown slope is fitted to the following data 
    \begin{table}[H]
        \centering
        \begin{tabular}{|c|c|c|c|c|c|}
\hline
   $x$  & $-2$ & $-1$ & 0 & 1 & 2 \\
   \hline
    $y$ & 3 & 5 & 8 & 9 & 10 \\
    \hline
\end{tabular}
    \end{table}
    using the method of ordinary least squares. Then the predicted value of $y$ corresponding to $x = 5$ is \rule{2cm}{0.4pt}

    \hfill [2020 ST]
    \item Let $D = \cbrak{\brak{x,y,z} \in \mathbb{R}\times \mathbb{R}\times \mathbb{R} : 0 \leq x,y,z \leq 1, x + y + z \leq 1}$ where $\mathbb{R}$ denotes the set of all real numbers to $x 5$. If 
    \begin{center}
        $I = \int \int\limits_{ D} \int  \brak{x + y } dx dy dz$,
    \end{center}
    then $84 \times I = $ \rule{2cm}{0.4pt}

    \hfill [2020 ST]
    \item Let the random vector $\brak{X,Y}$ have the joint distribution function 
    \begin{center}
        $F(x,y) = 
        \begin{cases}
            0 & x < 0 \text{ or } y < 0 \\
            \frac{1 - e ^{-x}}{4} & x \geq 0, 0 \leq y < 1 \\
            1 - e^{-x}& x \geq 0, y \geq 1
        \end{cases}$
    \end{center}
    Let Var($X$) and Var($Y$) denote the variance $X$ and $Y$, then respectively. Then 
    \begin{center}
        16 Var($X$) + 32 Var($Y$) = \rule{2cm}{0.4pt}
    \end{center}
    \hfill [2020 ST]
    \item Let $\cbrak{X_n}_{n \geq 1}$ be a sequence of independent and identically distributed random variables with $E\brak{X_1} = 0$, $E\brak{X_1^2}$ and $E\brak{X_1^4} = 3$. Further, let 
\begin{center}
    $Y_n = \frac{X_1^2 + X_2^2 +  \cdots + X_n^2}{n}$
\end{center}
If
\begin{center}
    $\lim \limits_{n \to \infty} P \brak{Y_n + \frac{\sqrt{n}\brak{Y_n - 1}}{\sqrt{3}} \leq 2} = \Phi\brak{c}$,
\end{center}
where $\Phi\brak{.}$ denotes the cumulative distribution function of the standard normal distribution, then $c^2$ = \rule{2cm}{0.4pt}(correct up to one decimal place)

\hfill [2020 ST]
\item Let the random vector $\vec{X} = \brak{X_1, X_2, X_3}$ have the joint probability density function 
\begin{center}
    $f_{\vec{X}}\brak{x_1,x_2,x_3} = 
    \begin{cases}
    \frac{81}{4} x_1^2 x_2^2 x_3^2, & -1 \leq x_1 \leq x_2 \leq x_3 \leq 1, \\
0, & \text{otherwise}.
    \end{cases}$ 
\end{center}
    
    Then the variable of the random variable $X_1 + X_2 + X_3$ equals \rule{2cm}{0.4pt}
    (correct up to one decimal place) \hfill[2020 ST]
    \item Let $X_1, \ldots ,X_5$ be a random sample from a distribution with the probability density function
    \begin{center}
        $f\brak{x;\theta} = \frac{1}{2}e^{- \abs{x - \theta}}, x \in \brak{-\infty, \infty}$,
    \end{center}   
    where $\theta \in \brak{-\infty, \infty}$. For testing $H_0 : \theta = 0$ against $H_1 : \theta < 0, \text{ let }  \sum_{i=1}^5 Y_i$  be the sign test statistic, where \\
    \begin{center}
        
     $Y_i = 
     \begin{cases}
         1, & X > 0  \\
         0, & \text{otherwise}
     \end{cases}$
    \end{center}
    Then the size of the test, which rejects $H_0$ if and only if $\sum_{i = 1}^5 Y_i \leq 2$, equals \rule{2cm}{0.4pt} (correct up to one decimal place). \hfill[2020 ST]
